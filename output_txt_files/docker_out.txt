PS C:\Users\tszyborski\Documents\DevOps_Microservices> docker run -p 8000:80 ml-api
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 325-332-290
172.17.0.1 - - [13/Sep/2021 18:24:14] "GET / HTTP/1.1" 200 -
172.17.0.1 - - [13/Sep/2021 18:24:14] "GET /favicon.ico HTTP/1.1" 404 -
[2021-09-13 18:25:03,051] INFO in app: JSON payload:
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2021-09-13 18:25:03,064] INFO in app: Inference payload DataFrame:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2021-09-13 18:25:03,072] INFO in app: Scaling Payload:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2021-09-13 18:25:03,074] INFO in app: Prediction output: [20.35373177134412]
172.17.0.1 - - [13/Sep/2021 18:25:03] "POST /predict HTTP/1.1" 200 -